apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: amt-arena-acl-alerts
  namespace: amt
  labels:
    team: amt
spec:
  groups:
    - name: amt-arena-acl-alerts
      rules:
        - alert: applikasjon nede
          expr: kube_deployment_status_replicas_available{deployment="amt-arena-acl"} == 0
          for: 2m
          annotations:
            summary: "App {{ $labels.deployment }} er nede i namespace {{ $labels.namespace }}"
            action: "`kubectl describe pod -l app={{ $labels.deployment}}` -> `kubectl logs -l app={{ $labels.deployment}}`"
          labels:
            namespace: amt
            severity: critical
        - alert: høy feilrate i logger
          expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="amt-arena-acl",log_level=~"Warning|Error"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="amt-arena-acl"}[3m]))) > 10
          for: 3m
          annotations:
            action: "Sjekk loggene til app amt-arena-acl i namespace amt, for å se hvorfor det er så mye feil"
          labels:
            namespace: amt
            severity: warning
        - alert: feil logges
          expr: sum by(log_app, log_namespace) (increase(logd_messages_total{log_app="amt-arena-acl",log_level=~"Error"}[5m])) > 0
          for: 5m
          annotations:
            action: "Sjekk loggene til app amt-arena-acl i namespace amt, for å se hva som feiler"
          labels:
            namespace: amt
            severity: warning
        - alert: antall meldinger i arena-acl med status FAILED > 0
          expr: amt_arena_acl_ingest_status{app="amt-arena-acl", status="FAILED"} > 0
          for: 1m
          annotations:
            action: "Sjekk `arena_data` tabellen: `select * from arena_data where ingest_status = 'FAILED';`"
          labels:
            namespace: amt
            severity: critical