apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: amt-arena-acl-alerts-1
  namespace: amt
  labels:
    team: amt
spec:
  receivers:
    slack:
      channel: 'team_komet_alerts'
      prependText: '<!here> | '
  alerts:
    - alert: amt-arena-acl er nede
      expr: kube_deployment_status_replicas_available{deployment="amt-arena-acl"} == 0
      for: 2m
      description: "App {{ $labels.log_app }} er nede i namespace {{ $labels.kubernetes_namespace }}"
      action: "`kubectl describe pod {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for logger"
    - alert: høy feilrate i logger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="amt-tiltak",log_level=~"Warning|Error"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="amt-tiltak"}[3m]))) > 10
      for: 3m
      action: "Sjekk loggene til app {{ $labels.log_app }} i namespace {{ $labels.log_namespace }}, for å se hvorfor det er så mye feil"

---

apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: amt-arena-acl-alerts-2
  namespace: amt
  labels:
    team: amt
spec:
  receivers:
    slack:
      channel: 'team_komet_alerts'
      prependText: '<!here> | '
  alerts:
    - alert: antall meldinger i arena-acl med status FAILED > 0
      expr: amt_arena_acl_ingest_status{app="amt-arena-acl", status="FAILED"} >= 0
      action: "Sjekk `arena_data` tabellen: `select * from arena_data where ingest_status = 'FAILED';`"
      for: 1m
  route:
    repeatInterval: 12h